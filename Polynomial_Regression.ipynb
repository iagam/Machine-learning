{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression,Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_friedman1(n_samples = 100,\n",
    "                           n_features = 7, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear model coeff (w): [ 4.90097795  5.97038291  0.26725167  9.91063395  6.44826569 -2.181019\n",
      " -0.43662574]\n",
      "linear model intercept (b): 1.813\n",
      "R-squared score (training): 0.717\n",
      "R-squared score (test): 0.752\n",
      "\n",
      "Now we transform the original input data to add\n",
      "polynomial features up to degree 2 (quadratic)\n",
      "\n",
      "(poly deg 2) linear model coeff (w):\n",
      "[ 3.40951018e-12  1.66452443e+01  2.67285381e+01 -2.21348316e+01\n",
      "  1.24359227e+01  6.93086826e+00  1.04772675e+00  3.71352773e+00\n",
      " -1.33785505e+01 -5.73177185e+00  1.61813184e+00  3.66399592e+00\n",
      "  5.04513181e+00 -1.45835979e+00  1.95156872e+00 -1.51297378e+01\n",
      "  4.86762224e+00 -2.97084269e+00 -7.78370522e+00  5.14696078e+00\n",
      " -4.65479361e+00  1.84147395e+01 -2.22040650e+00  2.16572630e+00\n",
      " -1.27989481e+00  1.87946559e+00  1.52962716e-01  5.62073813e-01\n",
      " -8.91697516e-01 -2.18481128e+00  1.37595426e+00 -4.90336041e+00\n",
      " -2.23535458e+00  1.38268439e+00 -5.51908208e-01 -1.08795007e+00]\n",
      "(poly deg 2) linear model intercept (b): -3.206\n",
      "(poly deg 2) R-squared score (training): 0.969\n",
      "(poly deg 2) R-squared score (test): 0.805\n",
      "\n",
      "\n",
      "Addition of many polynomial features often leads to\n",
      "overfitting, so we often use polynomial features in combination\n",
      "with regression that has a regularization penalty, like ridge\n",
      "regression.\n",
      "\n",
      "(poly deg 2 + ridge) linear model coeff (w):\n",
      "[ 0.          2.229281    4.73349734 -3.15432089  3.8585194   1.60970912\n",
      " -0.76967054 -0.14956002 -1.75215371  1.5970487   1.37080607  2.51598244\n",
      "  2.71746523  0.48531538 -1.9356048  -1.62914955  1.51474518  0.88674141\n",
      "  0.26141199  2.04931775 -1.93025705  3.61850966 -0.71788143  0.63173956\n",
      " -3.16429847  1.29161448  3.545085    1.73422041  0.94347654 -0.51207219\n",
      "  1.70114448 -1.97949067  1.80687548 -0.2173863   2.87585898 -0.89423157]\n",
      "(poly deg 2 + ridge) linear model intercept (b): 5.418\n",
      "(poly deg 2 + ridge) R-squared score (training): 0.826\n",
      "(poly deg 2 + ridge) R-squared score (test): 0.825\n"
     ]
    }
   ],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "print('linear model coeff (w): {}'\n",
    "     .format(linreg.coef_))\n",
    "print('linear model intercept (b): {:.3f}'\n",
    "     .format(linreg.intercept_))\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linreg.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linreg.score(X_test, y_test)))\n",
    "\n",
    "print('\\nNow we transform the original input data to add\\n\\\n",
    "polynomial features up to degree 2 (quadratic)\\n')\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y,\n",
    "                                                   random_state = 0)\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print('(poly deg 2) linear model coeff (w):\\n{}'\n",
    "     .format(linreg.coef_))\n",
    "print('(poly deg 2) linear model intercept (b): {:.3f}'\n",
    "     .format(linreg.intercept_))\n",
    "print('(poly deg 2) R-squared score (training): {:.3f}'\n",
    "     .format(linreg.score(X_train, y_train)))\n",
    "print('(poly deg 2) R-squared score (test): {:.3f}\\n'\n",
    "     .format(linreg.score(X_test, y_test)))\n",
    "\n",
    "print('\\nAddition of many polynomial features often leads to\\n\\\n",
    "overfitting, so we often use polynomial features in combination\\n\\\n",
    "with regression that has a regularization penalty, like ridge\\n\\\n",
    "regression.\\n')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y,\n",
    "                                                   random_state = 0)\n",
    "linreg = Ridge().fit(X_train, y_train)\n",
    "\n",
    "print('(poly deg 2 + ridge) linear model coeff (w):\\n{}'\n",
    "     .format(linreg.coef_))\n",
    "print('(poly deg 2 + ridge) linear model intercept (b): {:.3f}'\n",
    "     .format(linreg.intercept_))\n",
    "print('(poly deg 2 + ridge) R-squared score (training): {:.3f}'\n",
    "     .format(linreg.score(X_train, y_train)))\n",
    "print('(poly deg 2 + ridge) R-squared score (test): {:.3f}'\n",
    "     .format(linreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
